{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa0356-f2bb-45b2-8c8c-9afd8da8aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838d75a-8d53-4275-8b54-7c429bfac0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0270add-cd3c-41e5-9652-a28da7005847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_word, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "    Select only those subword token outputs that belong to our word of interest\n",
    "    and average them.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "\n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "    # Only select the tokens that constitute the requested word\n",
    "    word_tokens_output = output[token_ids_word]\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "\n",
    "def get_word_vector(sent, idx, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "    that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "\n",
    "    return get_hidden_states(encoded, token_ids_word, model, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a20d8e-4634-469a-a6d7-5173947a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [-4, -3, -2, -1]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc247c0b-cd0b-4518-8ba7-044b220a22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"I like cookies .\"\n",
    "# idx = get_word_idx(sent, \"cookies\")\n",
    "sent = \"switch leap with 0.5 turn\"\n",
    "idx = get_word_idx(sent, \"with\")\n",
    "\n",
    "word_embedding = get_word_vector(sent, idx, tokenizer, model, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f520fd-7bda-43c3-9018-3c87e4bbecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19189e-2bf5-4e31-af73-6327c572cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding.min(), word_embedding.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67562a-e0aa-4f6b-9ae2-ab74382df164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
